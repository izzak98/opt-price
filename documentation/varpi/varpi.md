# VarPi Documentation

VarPi is the second stage of the qStorm pipeline. It learns to predict quantiles of random walk distributions (cumulative returns) from quantiles of return distributions (varphi).

## Overview

**Purpose**: Predict quantiles of random walk distributions given return distribution quantiles

**Model Type**: Deep Multi-Layer Perceptron (MLP)

**Input**: 
- Varphi quantiles (37 values)
- Normalized time position (t/T)
- Normalized total walk length (T/30)

**Output**: 37 quantiles of random walk distribution at time t

## Architecture

### Network Structure

Deep MLP with decreasing hidden dimensions:
```
Input (39) → 4096 → 4096 → 4096 → 2048 → 2048 → 1024 → 256 → 256 → 64 → 32 → Output (37)
```

**Input Layer**: 
- 37 quantiles from varphi
- 1 normalized time position (t/T)
- 1 normalized total walk length (T/30)
- **Total**: 39 features

**Hidden Layers**:
- Linear layers with ReLU activation
- Decreasing dimensions for hierarchical feature extraction

**Output Layer**:
- 37 quantiles (same as input)
- Quantiles are sorted to ensure monotonicity

### Forward Pass

```python
def forward(self, q, t, T):
    # Concatenate inputs
    X = torch.cat([q, t, T], dim=1)
    
    # Forward through network
    f = self.input_layer(X)
    for layer in self.layers:
        f = layer(f)
    u = self.output_layer(f)
    
    # Sort quantiles (quantile function must be non-decreasing)
    u, _ = torch.sort(u)
    return u
```

## Training

### Dataset

**Source**: `walk_dataset.pkl` generated by `gen_walks.py`

**Structure**: Each sample contains:
- `q`: Varphi quantiles (37 values)
- `t`: Normalized time position (t/T)
- `T`: Normalized total walk length (T/30)
- `tq`: True random walk quantiles at time t (37 values)

**Split**: 70% train, 20% validation, 10% test

### Loss Function

**Mean Absolute Error (MAE)**:
```
L = mean(|q_pred - q_true|)
```

Unlike quantile loss, MAE treats all quantiles equally, which is appropriate since we're predicting the full quantile function.

### Training Procedure

1. Load random walk dataset
2. Split into train/val/test
3. Create model with architecture: [4096, 4096, 4096, 2048, 2048, 1024, 256, 256, 64, 32]
4. Train with:
   - Adam optimizer (lr=5e-4)
   - StepLR scheduler (reduce by 0.5x every 10 epochs)
   - MAE loss
   - Early stopping (patience=10)
   - Maximum 100 epochs

### Training Loop

```python
for epoch in range(epochs):
    for q, t, T, tq in train_loader:
        # Forward pass
        u = model(q, t, T)
        
        # Compute loss
        loss = mae_loss(u, tq)
        
        # Backpropagation
        loss.backward()
        optimizer.step()
    
    # Validation
    val_loss = validate(model, val_loader)
    
    # Early stopping
    if val_loss < best_val_loss:
        save_best_model()
    elif patience_exceeded:
        break
```

## Why This Architecture?

### Deep Network

The mapping from return quantiles to walk quantiles is complex:
- Involves convolution of distributions
- Non-linear relationship
- Time-dependent behavior

The deep architecture (10 layers) enables learning this complex mapping.

### Decreasing Dimensions

Hierarchical feature extraction:
- Early layers: Extract high-level patterns
- Middle layers: Combine features
- Late layers: Refine predictions

### Quantile Sorting

Quantile functions must be non-decreasing. Sorting the output ensures:
- Valid quantile function
- Mathematical consistency
- Better training stability

## Inference

### Usage in qStorm

VarPi is used during qStorm training to predict random walk quantiles:

```python
# Get varphi quantiles
varphi_quants = varphi_model(features)

# Predict walk quantiles at time t
walk_quants = varpi_model(varphi_quants, t/T, T/30)
```

### Model Loading

```python
import torch
varpi_model = torch.load('models/varpi.pth', weights_only=False)
varpi_model.eval()
```

## Key Features

### Generalization

VarPi learns a general mapping that works across:
- Different asset classes
- Different time horizons (T ∈ [15, 30])
- Different time positions (t ∈ [0, T-1])

### Nonparametric

No assumptions about return distributions:
- Works with any distribution shape
- Captures tail behavior
- Handles skewness and kurtosis

### Time-Aware

The model explicitly uses time information:
- Normalized time position (t/T) captures where in the walk
- Normalized total length (T/30) captures walk duration

## Model Files

- **Training**: `varpi/tain_varpi.py`
- **Model Definition**: `varpi/tain_varpi.py` (VarPi class)
- **Dataset Generation**: `varpi/gen_walks.py`
- **Trained Model**: `models/varpi.pth`

## Performance

### Training Time

- Dataset size: ~millions of samples
- Training time: ~hours on GPU
- Early stopping typically triggers around epoch 20-30

### Model Size

- Parameters: ~50M (due to large hidden dimensions)
- Model file: ~200MB

### Accuracy

- Test MAE: Typically < 0.01 (on normalized quantiles)
- Captures full distribution including tails

## References

- See `varpi/tain_varpi.py` for implementation
- See `varpi/gen_walks.py` for dataset generation
- See qStorm paper for theoretical background

