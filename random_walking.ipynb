{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaddicus/miniconda3/envs/opt-price/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff17b381bf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "from varpi.wasserstein_min import get_best_lstm_pdf_params\n",
    "from varpi.varpi_utils.varphi_utils import get_all_quantiles\n",
    "from utils.dist_utils import generate_smooth_pdf\n",
    "from utils.optuna_utils import load_qlstm_model\n",
    "from utils.data_utils import get_test_dataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "taus = CONFIG[\"general\"][\"quantiles\"]\n",
    "\n",
    "test_start_date = CONFIG[\"general\"][\"dates\"][\"test_period\"][\"start_date\"]\n",
    "test_end_date = CONFIG[\"general\"][\"dates\"][\"test_period\"][\"end_date\"]\n",
    "\n",
    "val_start_date = CONFIG[\"general\"][\"dates\"][\"validation_period\"][\"start_date\"]\n",
    "val_end_date = CONFIG[\"general\"][\"dates\"][\"validation_period\"][\"end_date\"]\n",
    "\n",
    "seed = CONFIG[\"general\"][\"seed\"]\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlstm_model, qlstm_params = load_qlstm_model()\n",
    "qlstm_model.load_state_dict(torch.load('models/qlstm_model.pth'))\n",
    "qlstm_model = qlstm_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infrence the Model to get all S&P500 tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = 30\n",
    "# for T in range(15, 31):\n",
    "#     folder_name = \"stored_quants\"\n",
    "#     normalization_window = qlstm_params['normalazation_window']\n",
    "#     val_dataset = get_test_dataset(normalization_lookback=normalization_window,\n",
    "#                                     start_date=val_start_date,\n",
    "#                                     end_date=val_end_date,\n",
    "#                                     lookforward=T,\n",
    "#                                     test=True)\n",
    "#     test_quantiles = get_all_quantiles(val_dataset, qlstm_model)\n",
    "#     save_path = os.path.join(folder_name, f\"quantiles_{T}.pkl\")\n",
    "#     with open(save_path, 'wb') as f:\n",
    "#         pickle.dump(test_quantiles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing models: 100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n"
     ]
    }
   ],
   "source": [
    "normalization_window = qlstm_params['normalazation_window']\n",
    "val_dataset = get_test_dataset(normalization_lookback=normalization_window,\n",
    "                                    start_date=val_start_date,\n",
    "                                    end_date=val_end_date,\n",
    "                                    lookforward=30,\n",
    "                                    test=True)\n",
    "val_quantiles = get_all_quantiles(val_dataset, qlstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a random index to look at the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(val_quantiles[\"s&p 500\"][\"observed_returns\"]))\n",
    "obs_rets = val_quantiles[\"s&p 500\"][\"observed_returns\"][idx]\n",
    "future_rets = val_quantiles[\"s&p 500\"][\"future_returns\"][idx]\n",
    "quants = val_quantiles[\"s&p 500\"][\"all_pred_quantiles\"][idx]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_params = get_best_lstm_pdf_params(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_mean = 0.0005\n",
    "desired_std = 0.05\n",
    "grid, pdf, cdf = generate_smooth_pdf(quants, np.array(taus), **pdf_params)\n",
    "quants_mean = np.mean(quants, axis=0)\n",
    "quants_std = np.std(quants, axis=0)\n",
    "new_quants = transform_quantiles(quants, desired_mean, desired_std, max_iterations=5, tolerance=1e-2)\n",
    "new_grid, new_pdf, new_cdf = generate_smooth_pdf(new_quants, np.array(taus), **pdf_params, grid_points=1000)\n",
    "\n",
    "standard_mean = np.trapz(grid * pdf, grid)\n",
    "standard_std = np.sqrt(np.trapz(grid ** 2 * pdf, grid) - standard_mean ** 2)\n",
    "\n",
    "new_mean = np.trapz(new_grid * new_pdf, new_grid)\n",
    "new_std = np.sqrt(np.trapz(new_grid ** 2 * new_pdf, new_grid) - new_mean ** 2)\n",
    "\n",
    "print(f\"Standard Mean: {standard_mean:.6f}, Standard Std: {standard_std:.6f}\")\n",
    "print(f\"New Mean: {new_mean:.6f}, New Std: {new_std:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(grid, pdf, label=\"Estimated PDF\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.xlabel(\"Returns\")\n",
    "plt.title(\"Estimated PDF of random ticker in S&P 500\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_walk(cdf, T):\n",
    "    random_uniform_samples = np.random.uniform(0, 1, T)\n",
    "    predicted_samples = np.interp(random_uniform_samples, cdf, grid)\n",
    "    predicted_samples = np.concatenate([[0], predicted_samples])\n",
    "    discrete_random_walk = np.cumsum(predicted_samples)\n",
    "    return discrete_random_walk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "random_walks = []\n",
    "for i in range(n_samples):\n",
    "    random_walks.append(generate_random_walk(cdf, 30))\n",
    "random_walks = np.array(random_walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for walk in random_walks:\n",
    "    plt.plot(walk)\n",
    "plt.ylabel(\"Cumulative Returns\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.title(\"Random Walks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_mean = np.trapz(grid * pdf, grid)\n",
    "pdf_std = np.sqrt(np.trapz((grid - pdf_mean) ** 2 * pdf, grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_mean = []\n",
    "theoretical_std = []\n",
    "\n",
    "empircal_mean = []\n",
    "empirical_std = []\n",
    "for i in range(30):\n",
    "    theoretical_mean.append(pdf_mean * i)\n",
    "    theoretical_std.append(pdf_std * np.sqrt(i))\n",
    "    \n",
    "    empircal_mean.append(np.mean(random_walks[:, i]))\n",
    "    empirical_std.append(np.std(random_walks[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(30)\n",
    "\n",
    "# Create the plots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 8), sharex=True, gridspec_kw={'hspace': 0.3})\n",
    "\n",
    "# First plot: Means\n",
    "axes[0].plot(x, theoretical_mean, label=\"Theoretical Mean\", linestyle=\"--\", color=\"blue\", linewidth=2)\n",
    "axes[0].plot(x, empircal_mean, label=\"Empirical Mean\", linestyle=\"-\", color=\"orange\", linewidth=2)\n",
    "axes[0].set_title(\"Mean Comparison\", fontsize=16)\n",
    "axes[0].set_ylabel(\"Mean Value\", fontsize=14)\n",
    "axes[0].grid(alpha=0.5)\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "\n",
    "# Second plot: Standard Deviations\n",
    "axes[1].plot(x, theoretical_std, label=\"Theoretical Std\", linestyle=\"--\", color=\"green\", linewidth=2)\n",
    "axes[1].plot(x, empirical_std, label=\"Empirical Std\", linestyle=\"-\", color=\"red\", linewidth=2)\n",
    "axes[1].set_title(\"Standard Deviation Comparison\", fontsize=16)\n",
    "axes[1].set_xlabel(\"Index\", fontsize=14)\n",
    "axes[1].set_ylabel(\"Standard Deviation Value\", fontsize=14)\n",
    "axes[1].grid(alpha=0.5)\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "# Add a unified title\n",
    "fig.suptitle(\"Theoretical vs Empirical Statistics\", fontsize=18, fontweight='bold')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(31):\n",
    "    if (i != 1 and i % 5 != 0 and i != 30) or i == 0:\n",
    "        continue\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(random_walks[:, i], bins=1000, density=True, alpha=0.5, label=\"Random Walks\")\n",
    "    emp_mean = np.mean(random_walks[:, i])\n",
    "    emp_std = np.std(random_walks[:, i])\n",
    "\n",
    "    min_val = np.min(random_walks[:, i])\n",
    "    max_val = np.max(random_walks[:, i])\n",
    "    \n",
    "    gaussian_grid = np.linspace(min_val, max_val, 10000)\n",
    "    gaussian_pdf = norm.pdf(gaussian_grid, loc=emp_mean, scale=emp_std)\n",
    "    \n",
    "    plt.plot(gaussian_grid, gaussian_pdf, label=\"Gaussian PDF\", color=\"red\", linewidth=2)\n",
    "    \n",
    "    if i == 1:\n",
    "        plt.plot(grid, pdf, label=\"Estimated PDF\", color=\"green\", linewidth=2)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.xlabel(\"Returns\")\n",
    "    plt.title(f\"Random Walk at day {i}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt-price",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
